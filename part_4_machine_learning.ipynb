{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "Python is an excellent choice for machine learning. The following two libraries are where most people start:\n",
    "\n",
    "_Sckikit Learn_\n",
    "\n",
    "[Scikit learn](http://scikit-learn.org/stable/) is the best place to get started with ML in Python. There are loads of good tutorials around and it's very easy to prototype and play around with.\n",
    "\n",
    "_TensorFlow_\n",
    "\n",
    "[Tensorflow](https://www.tensorflow.org/) is the \"serious\" machine learning library used by many professional machine learning engineers and researchers.  It's very versatile but can be intimidating for the beginner.\n",
    "\n",
    "## Basics\n",
    "\n",
    "The aim of machine learning is to \"learn\" on some sample dataset, then predict or classify some new unknown data.\n",
    "\n",
    "There are two broad categories:\n",
    "\n",
    "- **Supervised** - the training data comes with some additional attributes that we want to predict. This will normally be classification (i.e. labelling unlabelled data) or regression (predict some continuous variable given some input).\n",
    "\n",
    "- **Unsupervised** - the training data is not annotated and we want the system to \"discover\" some properties. This will usually be some sort of clustering or grouping.\n",
    "\n",
    "\n",
    "## Scikit Learn\n",
    "\n",
    "Scikit learn has a good set of [examples](http://scikit-learn.org/stable/auto_examples/index.html) and [tutorials](http://scikit-learn.org/stable/tutorial/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbours\n",
    "\n",
    "The nearest neighbours algorithm is a simple way to group data into a given number of clusters.\n",
    "\n",
    "We can start by loading the iris dataset. This is a list of measurements of iris flowers (sepal length, sepal width, petal length and petal width), plus the class of each flower (Setosa, Vesicolour and Virginica).\n",
    "\n",
    "We can load the iris dataset with scikit learn like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the values listed for the type of flower in the `target` property. This will be `0`, `1` or `2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that we can plot the result we only want to take the first two columns of data. The data in the dataset is found in `data` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5],\n",
       "       [4.9, 3. ],\n",
       "       [4.7, 3.2],\n",
       "       [4.6, 3.1],\n",
       "       [5. , 3.6],\n",
       "       [5.4, 3.9],\n",
       "       [4.6, 3.4],\n",
       "       [5. , 3.4],\n",
       "       [4.4, 2.9],\n",
       "       [4.9, 3.1],\n",
       "       [5.4, 3.7],\n",
       "       [4.8, 3.4],\n",
       "       [4.8, 3. ],\n",
       "       [4.3, 3. ],\n",
       "       [5.8, 4. ],\n",
       "       [5.7, 4.4],\n",
       "       [5.4, 3.9],\n",
       "       [5.1, 3.5],\n",
       "       [5.7, 3.8],\n",
       "       [5.1, 3.8],\n",
       "       [5.4, 3.4],\n",
       "       [5.1, 3.7],\n",
       "       [4.6, 3.6],\n",
       "       [5.1, 3.3],\n",
       "       [4.8, 3.4],\n",
       "       [5. , 3. ],\n",
       "       [5. , 3.4],\n",
       "       [5.2, 3.5],\n",
       "       [5.2, 3.4],\n",
       "       [4.7, 3.2],\n",
       "       [4.8, 3.1],\n",
       "       [5.4, 3.4],\n",
       "       [5.2, 4.1],\n",
       "       [5.5, 4.2],\n",
       "       [4.9, 3.1],\n",
       "       [5. , 3.2],\n",
       "       [5.5, 3.5],\n",
       "       [4.9, 3.1],\n",
       "       [4.4, 3. ],\n",
       "       [5.1, 3.4],\n",
       "       [5. , 3.5],\n",
       "       [4.5, 2.3],\n",
       "       [4.4, 3.2],\n",
       "       [5. , 3.5],\n",
       "       [5.1, 3.8],\n",
       "       [4.8, 3. ],\n",
       "       [5.1, 3.8],\n",
       "       [4.6, 3.2],\n",
       "       [5.3, 3.7],\n",
       "       [5. , 3.3],\n",
       "       [7. , 3.2],\n",
       "       [6.4, 3.2],\n",
       "       [6.9, 3.1],\n",
       "       [5.5, 2.3],\n",
       "       [6.5, 2.8],\n",
       "       [5.7, 2.8],\n",
       "       [6.3, 3.3],\n",
       "       [4.9, 2.4],\n",
       "       [6.6, 2.9],\n",
       "       [5.2, 2.7],\n",
       "       [5. , 2. ],\n",
       "       [5.9, 3. ],\n",
       "       [6. , 2.2],\n",
       "       [6.1, 2.9],\n",
       "       [5.6, 2.9],\n",
       "       [6.7, 3.1],\n",
       "       [5.6, 3. ],\n",
       "       [5.8, 2.7],\n",
       "       [6.2, 2.2],\n",
       "       [5.6, 2.5],\n",
       "       [5.9, 3.2],\n",
       "       [6.1, 2.8],\n",
       "       [6.3, 2.5],\n",
       "       [6.1, 2.8],\n",
       "       [6.4, 2.9],\n",
       "       [6.6, 3. ],\n",
       "       [6.8, 2.8],\n",
       "       [6.7, 3. ],\n",
       "       [6. , 2.9],\n",
       "       [5.7, 2.6],\n",
       "       [5.5, 2.4],\n",
       "       [5.5, 2.4],\n",
       "       [5.8, 2.7],\n",
       "       [6. , 2.7],\n",
       "       [5.4, 3. ],\n",
       "       [6. , 3.4],\n",
       "       [6.7, 3.1],\n",
       "       [6.3, 2.3],\n",
       "       [5.6, 3. ],\n",
       "       [5.5, 2.5],\n",
       "       [5.5, 2.6],\n",
       "       [6.1, 3. ],\n",
       "       [5.8, 2.6],\n",
       "       [5. , 2.3],\n",
       "       [5.6, 2.7],\n",
       "       [5.7, 3. ],\n",
       "       [5.7, 2.9],\n",
       "       [6.2, 2.9],\n",
       "       [5.1, 2.5],\n",
       "       [5.7, 2.8],\n",
       "       [6.3, 3.3],\n",
       "       [5.8, 2.7],\n",
       "       [7.1, 3. ],\n",
       "       [6.3, 2.9],\n",
       "       [6.5, 3. ],\n",
       "       [7.6, 3. ],\n",
       "       [4.9, 2.5],\n",
       "       [7.3, 2.9],\n",
       "       [6.7, 2.5],\n",
       "       [7.2, 3.6],\n",
       "       [6.5, 3.2],\n",
       "       [6.4, 2.7],\n",
       "       [6.8, 3. ],\n",
       "       [5.7, 2.5],\n",
       "       [5.8, 2.8],\n",
       "       [6.4, 3.2],\n",
       "       [6.5, 3. ],\n",
       "       [7.7, 3.8],\n",
       "       [7.7, 2.6],\n",
       "       [6. , 2.2],\n",
       "       [6.9, 3.2],\n",
       "       [5.6, 2.8],\n",
       "       [7.7, 2.8],\n",
       "       [6.3, 2.7],\n",
       "       [6.7, 3.3],\n",
       "       [7.2, 3.2],\n",
       "       [6.2, 2.8],\n",
       "       [6.1, 3. ],\n",
       "       [6.4, 2.8],\n",
       "       [7.2, 3. ],\n",
       "       [7.4, 2.8],\n",
       "       [7.9, 3.8],\n",
       "       [6.4, 2.8],\n",
       "       [6.3, 2.8],\n",
       "       [6.1, 2.6],\n",
       "       [7.7, 3. ],\n",
       "       [6.3, 3.4],\n",
       "       [6.4, 3.1],\n",
       "       [6. , 3. ],\n",
       "       [6.9, 3.1],\n",
       "       [6.7, 3.1],\n",
       "       [6.9, 3.1],\n",
       "       [5.8, 2.7],\n",
       "       [6.8, 3.2],\n",
       "       [6.7, 3.3],\n",
       "       [6.7, 3. ],\n",
       "       [6.3, 2.5],\n",
       "       [6.5, 3. ],\n",
       "       [6.2, 3.4],\n",
       "       [5.9, 3. ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_down_data = iris.data[:, :2]\n",
    "cut_down_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we split up the data we need to shuffle it around. We can do this with `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data = np.random.permutation(cut_down_data)\n",
    "shuffled_target = np.random.permutation(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then take a certain proportion of each dataset as training/ testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data - take all but the last 10\n",
    "train_data = shuffled_data[:-10]\n",
    "train_target = shuffled_target[:-10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our training data we can train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Here is where we do the actual training\n",
    "knn.fit(train_data, train_target) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use our `knn` object to predict the class of the remaining target data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [0 1 0 0 1 1 1 0 0 1]\n",
      "Actual:    [1 2 0 1 2 0 1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "test_data = shuffled_data[-10:]\n",
    "test_target = shuffled_target[-10:]\n",
    "\n",
    "predicted_target = knn.predict(test_data)\n",
    "\n",
    "print('Predicted: {}'.format(predicted_target))\n",
    "print('Actual:    {}'.format(test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Have a look at the Scikit learn [linear regression example](http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html). \n",
    "\n",
    "Copy the code into this notebook and see if you can work out what it's doing.\n",
    "\n",
    "What happens if you reduce the size of the training data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
