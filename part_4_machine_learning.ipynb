{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets, svm, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "Python is an excellent choice for machine learning. The following two libraries are where most people start:\n",
    "\n",
    "_Sckikit Learn_\n",
    "\n",
    "[Scikit learn](http://scikit-learn.org/stable/) is the best place to get started with ML in Python. There are loads of good tutorials around and it's very easy to prototype and play around with.\n",
    "\n",
    "_TensorFlow_\n",
    "\n",
    "[Tensorflow](https://www.tensorflow.org/) is the \"serious\" machine learning library used by many professional machine learning engineers and researchers.  It's very versatile but can be intimidating for the beginner.\n",
    "\n",
    "## Basics\n",
    "\n",
    "The aim of machine learning is to \"learn\" on some sample dataset, then predict or classify some new unknown data.\n",
    "\n",
    "There are two broad categories:\n",
    "\n",
    "- **Supervised** - the training data comes with some additional attributes that we want to predict. This will normally be classification (i.e. labelling unlabelled data) or regression (predict some continuous variable given some input).\n",
    "\n",
    "- **Unsupervised** - the training data is not annotated and we want the system to \"discover\" some properties. This will usually be some sort of clustering or grouping.\n",
    "\n",
    "\n",
    "## Scikit Learn\n",
    "\n",
    "Scikit learn has a good set of [examples](http://scikit-learn.org/stable/auto_examples/index.html) and [tutorials](http://scikit-learn.org/stable/tutorial/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognising digits\n",
    "\n",
    "One of the canonical machine learning examples is recognising digits from the MNIST database. The Scikit learn example is shown [here](http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html) with a much longer discussion [here](http://scikit-learn.org/stable/tutorial/basic/tutorial.html).\n",
    "\n",
    "We begin by loading in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is structured as an 8x8 matrix of pixels. We can print the first one like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.],\n",
       "       [  0.,   0.,  13.,  15.,  10.,  15.,   5.,   0.],\n",
       "       [  0.,   3.,  15.,   2.,   0.,  11.,   8.,   0.],\n",
       "       [  0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.],\n",
       "       [  0.,   5.,   8.,   0.,   0.,   9.,   8.,   0.],\n",
       "       [  0.,   4.,  11.,   0.,   1.,  12.,   7.,   0.],\n",
       "       [  0.,   2.,  14.,   5.,  10.,  12.,   0.,   0.],\n",
       "       [  0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are stored in the `target` property, i.e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a feel for what this looks like, we can plot the labels against examples of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f590fa186d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier doesn't understand matrices so we need to reshape each image into a single vector of pixel values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(digits.images)\n",
    "\n",
    "# Note, the -1 is equivalent to saying \"automatically detect this\"\n",
    "data = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we see that the image is actually a single 1x64 vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to split our data into training set vs testing set. Let's take the first half as training and the second half as test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note integer division here\n",
    "n_training = n_samples // 2\n",
    "\n",
    "training_images = data[:n_training]\n",
    "test_images = data[n_training:]\n",
    "\n",
    "training_labels = digits.target[:n_training]\n",
    "test_labels = digits.target[n_training:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use a [support vector machine](http://scikit-learn.org/stable/modules/svm.html) via the scikit learn [support vector classifier](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) to create our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC(gamma=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(training_images, training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict the labels for the test image data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = classifier.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can display the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f590c5e6c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
    "\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:10]):\n",
    "    plt.subplot(2, 5, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbours\n",
    "\n",
    "The nearest neighbours algorithm is a simple way to group data into a given number of clusters.\n",
    "\n",
    "We can start by loading the iris dataset. This is a list of measurements of iris flowers (sepal length, sepal width, petal length and petal width), plus the class of each flower (Setosa, Vesicolour and Virginica).\n",
    "\n",
    "We can load the iris dataset with scikit learn like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the values listed for the type of flower in the `target` property. This will be `0`, `1` or `2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that we can plot the result we only want to take the first two columns of data. The data in the dataset is found in `data` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5],\n",
       "       [ 4.9,  3. ],\n",
       "       [ 4.7,  3.2],\n",
       "       [ 4.6,  3.1],\n",
       "       [ 5. ,  3.6],\n",
       "       [ 5.4,  3.9],\n",
       "       [ 4.6,  3.4],\n",
       "       [ 5. ,  3.4],\n",
       "       [ 4.4,  2.9],\n",
       "       [ 4.9,  3.1],\n",
       "       [ 5.4,  3.7],\n",
       "       [ 4.8,  3.4],\n",
       "       [ 4.8,  3. ],\n",
       "       [ 4.3,  3. ],\n",
       "       [ 5.8,  4. ],\n",
       "       [ 5.7,  4.4],\n",
       "       [ 5.4,  3.9],\n",
       "       [ 5.1,  3.5],\n",
       "       [ 5.7,  3.8],\n",
       "       [ 5.1,  3.8],\n",
       "       [ 5.4,  3.4],\n",
       "       [ 5.1,  3.7],\n",
       "       [ 4.6,  3.6],\n",
       "       [ 5.1,  3.3],\n",
       "       [ 4.8,  3.4],\n",
       "       [ 5. ,  3. ],\n",
       "       [ 5. ,  3.4],\n",
       "       [ 5.2,  3.5],\n",
       "       [ 5.2,  3.4],\n",
       "       [ 4.7,  3.2],\n",
       "       [ 4.8,  3.1],\n",
       "       [ 5.4,  3.4],\n",
       "       [ 5.2,  4.1],\n",
       "       [ 5.5,  4.2],\n",
       "       [ 4.9,  3.1],\n",
       "       [ 5. ,  3.2],\n",
       "       [ 5.5,  3.5],\n",
       "       [ 4.9,  3.1],\n",
       "       [ 4.4,  3. ],\n",
       "       [ 5.1,  3.4],\n",
       "       [ 5. ,  3.5],\n",
       "       [ 4.5,  2.3],\n",
       "       [ 4.4,  3.2],\n",
       "       [ 5. ,  3.5],\n",
       "       [ 5.1,  3.8],\n",
       "       [ 4.8,  3. ],\n",
       "       [ 5.1,  3.8],\n",
       "       [ 4.6,  3.2],\n",
       "       [ 5.3,  3.7],\n",
       "       [ 5. ,  3.3],\n",
       "       [ 7. ,  3.2],\n",
       "       [ 6.4,  3.2],\n",
       "       [ 6.9,  3.1],\n",
       "       [ 5.5,  2.3],\n",
       "       [ 6.5,  2.8],\n",
       "       [ 5.7,  2.8],\n",
       "       [ 6.3,  3.3],\n",
       "       [ 4.9,  2.4],\n",
       "       [ 6.6,  2.9],\n",
       "       [ 5.2,  2.7],\n",
       "       [ 5. ,  2. ],\n",
       "       [ 5.9,  3. ],\n",
       "       [ 6. ,  2.2],\n",
       "       [ 6.1,  2.9],\n",
       "       [ 5.6,  2.9],\n",
       "       [ 6.7,  3.1],\n",
       "       [ 5.6,  3. ],\n",
       "       [ 5.8,  2.7],\n",
       "       [ 6.2,  2.2],\n",
       "       [ 5.6,  2.5],\n",
       "       [ 5.9,  3.2],\n",
       "       [ 6.1,  2.8],\n",
       "       [ 6.3,  2.5],\n",
       "       [ 6.1,  2.8],\n",
       "       [ 6.4,  2.9],\n",
       "       [ 6.6,  3. ],\n",
       "       [ 6.8,  2.8],\n",
       "       [ 6.7,  3. ],\n",
       "       [ 6. ,  2.9],\n",
       "       [ 5.7,  2.6],\n",
       "       [ 5.5,  2.4],\n",
       "       [ 5.5,  2.4],\n",
       "       [ 5.8,  2.7],\n",
       "       [ 6. ,  2.7],\n",
       "       [ 5.4,  3. ],\n",
       "       [ 6. ,  3.4],\n",
       "       [ 6.7,  3.1],\n",
       "       [ 6.3,  2.3],\n",
       "       [ 5.6,  3. ],\n",
       "       [ 5.5,  2.5],\n",
       "       [ 5.5,  2.6],\n",
       "       [ 6.1,  3. ],\n",
       "       [ 5.8,  2.6],\n",
       "       [ 5. ,  2.3],\n",
       "       [ 5.6,  2.7],\n",
       "       [ 5.7,  3. ],\n",
       "       [ 5.7,  2.9],\n",
       "       [ 6.2,  2.9],\n",
       "       [ 5.1,  2.5],\n",
       "       [ 5.7,  2.8],\n",
       "       [ 6.3,  3.3],\n",
       "       [ 5.8,  2.7],\n",
       "       [ 7.1,  3. ],\n",
       "       [ 6.3,  2.9],\n",
       "       [ 6.5,  3. ],\n",
       "       [ 7.6,  3. ],\n",
       "       [ 4.9,  2.5],\n",
       "       [ 7.3,  2.9],\n",
       "       [ 6.7,  2.5],\n",
       "       [ 7.2,  3.6],\n",
       "       [ 6.5,  3.2],\n",
       "       [ 6.4,  2.7],\n",
       "       [ 6.8,  3. ],\n",
       "       [ 5.7,  2.5],\n",
       "       [ 5.8,  2.8],\n",
       "       [ 6.4,  3.2],\n",
       "       [ 6.5,  3. ],\n",
       "       [ 7.7,  3.8],\n",
       "       [ 7.7,  2.6],\n",
       "       [ 6. ,  2.2],\n",
       "       [ 6.9,  3.2],\n",
       "       [ 5.6,  2.8],\n",
       "       [ 7.7,  2.8],\n",
       "       [ 6.3,  2.7],\n",
       "       [ 6.7,  3.3],\n",
       "       [ 7.2,  3.2],\n",
       "       [ 6.2,  2.8],\n",
       "       [ 6.1,  3. ],\n",
       "       [ 6.4,  2.8],\n",
       "       [ 7.2,  3. ],\n",
       "       [ 7.4,  2.8],\n",
       "       [ 7.9,  3.8],\n",
       "       [ 6.4,  2.8],\n",
       "       [ 6.3,  2.8],\n",
       "       [ 6.1,  2.6],\n",
       "       [ 7.7,  3. ],\n",
       "       [ 6.3,  3.4],\n",
       "       [ 6.4,  3.1],\n",
       "       [ 6. ,  3. ],\n",
       "       [ 6.9,  3.1],\n",
       "       [ 6.7,  3.1],\n",
       "       [ 6.9,  3.1],\n",
       "       [ 5.8,  2.7],\n",
       "       [ 6.8,  3.2],\n",
       "       [ 6.7,  3.3],\n",
       "       [ 6.7,  3. ],\n",
       "       [ 6.3,  2.5],\n",
       "       [ 6.5,  3. ],\n",
       "       [ 6.2,  3.4],\n",
       "       [ 5.9,  3. ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_down_data = iris.data[:, :2]\n",
    "cut_down_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we split up the data we need to shuffle it around. We can do this with `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data = np.random.permutation(cut_down_data)\n",
    "shuffled_target = np.random.permutation(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then take a certain proportion of each dataset as training/ testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data - take all but the last 10\n",
    "train_data = shuffled_data[:-10]\n",
    "train_target = shuffled_target[:-10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our training data we can train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Here is where we do the actual training\n",
    "knn.fit(train_data, train_target) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use our `knn` object to predict the class of the remaining target data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [0 1 0 1 0 0 0 0 0 0]\n",
      "Actual:    [0 1 0 2 1 0 2 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "test_data = shuffled_data[-10:]\n",
    "test_target = shuffled_target[-10:]\n",
    "\n",
    "predicted_target = knn.predict(test_data)\n",
    "\n",
    "print('Predicted: {}'.format(predicted_target))\n",
    "print('Actual:    {}'.format(test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Have a look at the Scikit learn [linear regression example](http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html). \n",
    "\n",
    "Copy the code into this notebook and see if you can work out what it's doing.\n",
    "\n",
    "What happens if you reduce the size of the training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Exercises\n",
    "\n",
    "We can visualise the iris classification from above using Matplotlib as in this example: http://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html\n",
    "\n",
    "Have a go at reproducing it and playing with some of the parameters to see how they affect the outcome.\n",
    "\n",
    "Another simple example is that of isotonic regression vs linear regression as demonstrated here: http://scikit-learn.org/stable/auto_examples/plot_isotonic_regression.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
